{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["# corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias', 'que hoy es viernes', 'uhhh viernes'])\n","\n","\n","# Genera un corpus de 50 sentencias diferentes para probar el algoritmo (Copilot)\n","# corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias', 'que hoy es viernes', 'uhhh viernes', 'hoy es un dia de sol', 'hoy es un dia de lluvia', 'hoy es un dia de nubes', 'hoy es un dia de viento', 'hoy es un dia de calor', 'hoy es un dia de frio', 'hoy es un dia de nieve', 'hoy es un dia de niebla', 'hoy es un dia de tormenta', 'hoy es un dia de granizo', 'mañana es un dia de sol', 'mañana es un dia de lluvia', 'mañana es un dia de nubes', 'mañana es un dia de viento', 'mañana es un dia de calor', 'mañana es un dia de frio', 'mañana es un dia de nieve', 'mañana es un dia de niebla', 'mañana es un dia de tormenta', 'mañana es un dia de granizo', 'ayer fue un dia de sol', 'ayer fue un dia de lluvia', 'ayer fue un dia de nubes', 'ayer fue un dia de viento', 'ayer fue un dia de calor', 'ayer fue un dia de frio', 'ayer fue un dia de nieve', 'ayer fue un dia de niebla', 'ayer fue un dia de tormenta', 'ayer fue un dia de granizo', 'hoy es un dia de sol', 'hoy es un dia de lluvia', 'hoy es un dia de nubes', 'hoy es un dia de viento', 'hoy es un dia de calor', 'hoy es un dia de frio', 'hoy es un dia de nieve', 'hoy es un dia de niebla', 'hoy es un dia de tormenta', 'hoy es un dia de granizo', 'hoy es un dia de sol', 'hoy es un dia de lluvia', 'hoy es un dia de nubes', 'hoy es un dia de viento', 'hoy es un dia de calor', 'hoy es un dia de frio', 'hoy es un dia de nieve', 'hoy es un dia de niebla', 'hoy es un dia de tormenta', 'hoy es un dia de granizo'])\n","# quitar duplicados (Copilot)\n","# corpus = np.unique(corpus)\n","# print(corpus)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias'], ['que', 'hoy', 'es', 'viernes'], ['uhhh', 'viernes']]\n","['que', 'muchas', 'de', 'es', 'uhhh', 'martes', 'gracias', 'viernes', 'hoy', 'dia', 'el']\n"]}],"source":["# separo cada oracion del corpus en una lista de terminos \n","corpusTerminos = [sentence.split() for sentence in corpus] #Copilot\n","print(corpusTerminos)\n","\n","# armo un vocabulario con los terminos unicos del corpus\n","vocabulario = set()\n","for sentence in corpusTerminos:\n","    for word in sentence:\n","        vocabulario.add(word)\n","\n","vocabulario = list(vocabulario)\n","print(vocabulario)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario\n","['que', 'muchas', 'de', 'es', 'uhhh', 'martes', 'gracias', 'viernes', 'hoy', 'dia', 'el']\n","oneHotEncoding\n","[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n","['que', 'dia', 'es', 'hoy']\n","[1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n","['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","[0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n","['martes', 'muchas', 'gracias']\n","[0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n","['que', 'hoy', 'es', 'viernes']\n","[1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n","['uhhh', 'viernes']\n","[0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n"]}],"source":["# hago un one-hot encoding de cada palabra del vocabulario\n","oneHotEncoding = np.eye(len(vocabulario))#Copilot\n","print('vocabulario')\n","print(vocabulario)\n","print('oneHotEncoding')\n","print(oneHotEncoding)\n","\n","# hago la representacion en oneHotEncoding de cada oracion del corpus\n","corpusOneHot = []\n","for sentence in corpusTerminos:\n","    sentenceOneHot = np.zeros(len(vocabulario))\n","    for word in sentence:\n","        sentenceOneHot[vocabulario.index(word)] = 1\n","    corpusOneHot.append(sentenceOneHot)\n","    print(sentence)\n","    print(sentenceOneHot)\n","\n","\n","# print('corpusOneHot')\n","# print(corpusOneHot)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["['que', 'dia', 'es', 'hoy']\n","[1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n","['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","[0. 0. 1. 1. 0. 2. 0. 0. 1. 1. 1.]\n","['martes', 'muchas', 'gracias']\n","[0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n","['que', 'hoy', 'es', 'viernes']\n","[1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n","['uhhh', 'viernes']\n","[0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n","tf\n","[array([1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.]), array([0., 0., 1., 1., 0., 2., 0., 0., 1., 1., 1.]), array([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.]), array([1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])]\n"]}],"source":["# hago la representacion en oneHotEncoding de cada oracion del corpus para ver la frecuncia de cada palabra\n","tf = []\n","for sentence in corpusTerminos:\n","    sentenceTF = np.zeros(len(vocabulario))\n","    for word in sentence:\n","        sentenceTF[vocabulario.index(word)] += 1\n","    tf.append(sentenceTF)\n","    print(sentence)\n","    print(sentenceTF)\n","\n","print('tf')\n","print(tf)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["df\n","[2. 1. 1. 3. 1. 2. 1. 2. 3. 2. 1.]\n","idf\n","[0.91629073 1.60943791 1.60943791 0.51082562 1.60943791 0.91629073\n"," 1.60943791 0.91629073 0.51082562 0.91629073 1.60943791]\n","corpusTfIdf\n","[array([0.91629073, 0.        , 0.        , 0.51082562, 0.        ,\n","       0.        , 0.        , 0.        , 0.51082562, 0.91629073,\n","       0.        ]), array([0.        , 0.        , 1.60943791, 0.51082562, 0.        ,\n","       1.83258146, 0.        , 0.        , 0.51082562, 0.91629073,\n","       1.60943791]), array([0.        , 1.60943791, 0.        , 0.        , 0.        ,\n","       0.91629073, 1.60943791, 0.        , 0.        , 0.        ,\n","       0.        ]), array([0.91629073, 0.        , 0.        , 0.51082562, 0.        ,\n","       0.        , 0.        , 0.91629073, 0.51082562, 0.        ,\n","       0.        ]), array([0.        , 0.        , 0.        , 0.        , 1.60943791,\n","       0.        , 0.        , 0.91629073, 0.        , 0.        ,\n","       0.        ])]\n"]}],"source":["# calcula el indice de frecuencia de cada palabra del vocabulario\n","df = np.zeros(len(vocabulario))\n","# recorro volcabulario\n","for word, i in zip(vocabulario, range(len(vocabulario))):\n","    # recorro cada oracion del corpus\n","    for sentence in corpusTerminos:\n","        # si la palabra esta en la oracion, sumo 1 al indice de frecuencia\n","        if word in sentence:\n","            df[i] += 1\n","\n","# Lo anterior se genero por Copilot a partir de las descripciones en comentarios.\n","\n","print('df')\n","print(df)\n","\n","# calcula el indice de frecuencia inversa de cada palabra del vocabulario\n","idf = np.log(len(corpus) / df)\n","print('idf')\n","print(idf)\n","\n","# calcula la representacion tf-idf de cada oracion del corpus\n","corpusTfIdf = []\n","for sentence in tf:\n","    corpusTfIdf.append(sentence * idf)\n","\n","print('corpusTfIdf')\n","print(corpusTfIdf)\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["[3, 0, 4, 1, 2]\n","oracion buscada\n","que hoy es viernes\n","-------------\n","que hoy es viernes\n","que dia es hoy\n","uhhh viernes\n","martes el dia de hoy es martes\n","martes muchas gracias\n"]}],"source":["def similitudCoseno(corpus, indice): #recibe el corpus procesado con TF-IDF y el indice de la oracion a comparar, devuelve los idices de las oraciones del corpus ordenadas por similitud coseno\n","    # comparo la oracion con todas las oraciones del corpus\n","    similitudes = []\n","    for i in range(len(corpus)):\n","        similitudes.append([cosine_similarity(corpus[indice], corpus[i]), i]) #Copilot y modificado a mano\n","\n","    # ordeno las similitudes de mayor a menor segun el coseno\n","    similitudes.sort( key=lambda x: x[0], reverse=True ) #Copilot\n","\n","    # deja solo los indices de las oraciones\n","    similitudes = [x[1] for x in similitudes] #Copilot\n","    return similitudes\n","\n","\n","indiceBuscado = 3\n","idexOrdenadas = similitudCoseno(corpusTfIdf, indiceBuscado)\n","print(idexOrdenadas)\n","\n","print('oracion buscada')\n","print(corpus[indiceBuscado])\n","print('-------------')\n","\n","for i in idexOrdenadas:\n","    print(corpus[i])\n","    "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
